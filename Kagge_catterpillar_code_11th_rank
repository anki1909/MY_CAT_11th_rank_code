
"""
This file i am using, and currently i have 13 ranks on LB , i am using fill material-3+number_of itemsper tube,bill_of_materials

@author: Pahadi

([u'tube_assembly_id', u'supplier', u'quote_date', u'annual_usage',
       u'min_order_quantity', u'bracket_pricing', u'quantity', u'cost',
       u'material_id', u'diameter', u'wall', u'length', u'num_bends',
       u'bend_radius', u'end_a_1x', u'end_a_2x', u'end_x_1x', u'end_x_2x',
       u'end_a', u'end_x', u'num_boss', u'num_bracket', u'other',
       u'component_id_1', u'quantity_1', u'component_id_2', u'quantity_2',
       u'component_id_3', u'quantity_3', u'component_id_4', u'quantity_4',
       u'component_id_5', u'quantity_5', u'component_id_6', u'quantity_6',
       u'component_id_7', u'quantity_7', u'component_id_8', u'quantity_8'],
      ='object')
# -*- coding: utf-8 -*-

Created on Wed Jul 01 22:29:53 2015

'tube_assembly_id' 'supplier' 'quote_date' 'annual_usage' 'min_order_quantity' 'bracket_pricing' 'quantity' 'cost'

@author: Pahadi
"""




from sklearn import ensemble, preprocessing, grid_search, cross_validation
import pandas as pd
import numpy as np
from sklearn import ensemble , preprocessing
from sklearn.utils import shuffle
from sklearn.metrics import mean_squared_error


if __name__ == '__main__':
    # load training and test datasets
    train = pd.read_csv('D:/carterpiller/competition_data/filledmaterialtrain3.csv' , parse_dates=[2,])#, nrows =1000)
    test = pd.read_csv('D:/carterpiller/competition_data/filledmaterialtest3.csv', parse_dates=[3,] )#, nrows = 1000)
    num_items_train = pd.read_csv('D:/carterpiller/competition_data/number_of_items_per_tube_train.csv')#, nrows = 1000 )
    num_items_test =  pd.read_csv('D:/carterpiller/competition_data/number_of_items_per_tube_test.csv' )#, nrows = 1000 )  
    #freq_compo_train = pd.read_csv('D:/carterpiller/competition_data/freq_compo_bill_train.csv' )#, nrows = 1000 )    
    #freq_compo_test = pd.read_csv('D:/carterpiller/competition_data/freq_compo_bill_test.csv' )#, nrows = 1000 )    
    bill = pd.read_csv('D:/carterpiller/competition_data/bill_ofmatarials.csv' )#, nrows = 1000 )
    num_spec_train = pd.read_csv('D:/carterpiller/competition_data/num_spec_train.csv')# nrows = 1000 )
    num_spec_test = pd.read_csv('D:/carterpiller/competition_data/num_spec_test.csv')# nrows = 1000 )
    freq_spec_train = pd.read_csv('D:/carterpiller/competition_data/specs_train_merged.csv')
    freq_spec_test = pd.read_csv('D:/carterpiller/competition_data/specs_test_merged.csv')
    #print train.shape , train.columns
    
    
    print type(test.supplier[0])
    
    
    train = pd.merge(train, bill, on ='tube_assembly_id')
    test = pd.merge(test, bill, on ='tube_assembly_id')
    
    
    
    #print train.shape , train.columns
    
    for i in range(1,9):
        column_label = 'component_id_'+str(i)
        #print(column_label)
        train[column_label].replace(np.nan,' ', regex=True, inplace= True)
        test[column_label].replace(np.nan,' ', regex=True, inplace= True)
    
    train.fillna(0, inplace = True)
    test.fillna(0, inplace = True)
    
    
    
    
    """
    print train.shape , test.shape
    k1 = 1/(train.annual_usage.astype(float)+10)
    train.loc['annual_usage'] = k1
    k1 = 1/(test.annual_usage.astype(float)+10)    
    test.loc['annual_usage'] = k1
    k1 = 1/(train.quantity.astype(float))
    train.loc['quantity1'] = 1/k1
    print 1/(train.annual_usage.astype(float)+10)
    """    
    
    print '1',train.columns
    
    train['annual_usage'] = 1/(train['annual_usage'].astype(float)+10)
    train['quantity'] = 1/train['quantity'].astype(float)
    
    test['annual_usage'] = 1/(test['annual_usage'].astype(float)+10)
    test['quantity'] = 1/test['quantity'].astype(float)
    

        
    
    train['interactions'] = 0
    test['interactions'] = 0


    
    
    
    for i in np.unique(test.tube_assembly_id): 
        test.loc[test.tube_assembly_id == i , 'interactions'] = 1/((test.loc[test.tube_assembly_id == i, 'annual_usage'].astype(float)+10) * test.loc[test.tube_assembly_id == i, 'quantity'].astype(float) )        
        #print  i ,1/((test.loc[test.tube_assembly_id == i, 'annual_usage'].astype(float)+10) * test.loc[test.tube_assembly_id == i, 'quantity'].astype(float) )
        #print train.loc[train.tube_assembly_id == i, 'quantity']



    #print test.loc[test.interactions.isnull(),'tube_assembly_id']

    for i in np.unique(train.tube_assembly_id): 
        train.loc[train.tube_assembly_id == i , 'interactions'] = 1/((train.loc[train.tube_assembly_id == i, 'annual_usage'].astype(float)+10) * train.loc[train.tube_assembly_id == i, 'quantity'].astype(float) )
        #print  i ,1/((train.loc[train.tube_assembly_id == i, 'annual_usage'].astype(float)+10) * train.loc[train.tube_assembly_id == i, 'quantity'].astype(float) )

    
    #print train.loc[train.interactions.isnull(),'tube_assembly_id']

   
   
    #print num_items_test.shape , num_items_train.shape , train.shape , test.shape    
    #specs = pd.read_csv('D:/carterpiller/competition_data/specs_parsed.csv' )
    #specs_test = pd.read_csv('D:/carterpiller/competition_data/specs_test_merged.csv' , parse_dates=[2,])
    #print train.columns.values
    # create some new features

    #fill bend_radius which is equal to 9999.0
    for i in np.unique(train.loc[train.bend_radius == 9999.0 , 'tube_assembly_id']):
        k =  train.loc[(train.tube_assembly_id == i) ,'length'].mean()
        j = train.loc[(train.tube_assembly_id == i) ,'num_bends'].mean()
        #print i,j,k
        #print k ,i , j , train.loc[(train.bend_radius == 9999.0) & (train.tube_assembly_id == i) , 'bend_radius'],'\n'
        train.loc[(train.bend_radius == 9999.0) & (train.tube_assembly_id == i) , 'bend_radius']\
        = train.loc[(train.length > k-5)& (train.num_bends > j-1) & (train.num_bends < j+1) &\
        (train.length < k+5) & (train.bend_radius != 9999.0) , 'bend_radius'].mean()
    
    
    


    # fill length(zero is not possible), admin has given this 
    train.loc[(train.tube_assembly_id == 'TA-00152') & (train.length == 0) , 'length'] = 19
    train.loc[(train.tube_assembly_id == 'TA-00154') & (train.length == 0) , 'length'] = 75
    train.loc[(train.tube_assembly_id == 'TA-00156') & (train.length == 0) , 'length'] = 24
    train.loc[(train.tube_assembly_id == 'TA-01098') & (train.length == 0) , 'length'] = 10
    train.loc[(train.tube_assembly_id == 'TA-01631') & (train.length == 0) , 'length'] = 48
    train.loc[(train.tube_assembly_id == 'TA-03520') & (train.length == 0) , 'length'] = 46
    train.loc[(train.tube_assembly_id == 'TA-04114') & (train.length == 0) , 'length'] = 135
    train.loc[(train.tube_assembly_id == 'TA-17390') & (train.length == 0) , 'length'] = 40
    train.loc[(train.tube_assembly_id == 'TA-18227') & (train.length == 0) , 'length'] = 74
    train.loc[(train.tube_assembly_id == 'TA-18229') & (train.length == 0) , 'length'] = 51
    
    #..................................... for test
    test.loc[(test.tube_assembly_id == 'TA-00152') & (train.length == 0) , 'length'] = 19
    test.loc[(test.tube_assembly_id == 'TA-00154') & (train.length == 0) , 'length'] = 75
    test.loc[(test.tube_assembly_id == 'TA-00156') & (train.length == 0) , 'length'] = 24
    test.loc[(test.tube_assembly_id == 'TA-01098') & (train.length == 0) , 'length'] = 10
    test.loc[(test.tube_assembly_id == 'TA-01631') & (train.length == 0) , 'length'] = 48
    test.loc[(test.tube_assembly_id == 'TA-03520') & (train.length == 0) , 'length'] = 46
    test.loc[(test.tube_assembly_id == 'TA-04114') & (train.length == 0) , 'length'] = 135
    test.loc[(test.tube_assembly_id == 'TA-17390') & (train.length == 0) , 'length'] = 40
    test.loc[(test.tube_assembly_id == 'TA-18227') & (train.length == 0) , 'length'] = 74
    test.loc[(test.tube_assembly_id == 'TA-18229') & (train.length == 0) , 'length'] = 51
    














    train['year'] = train.quote_date.dt.year
    train['month'] = train.quote_date.dt.month
    train['dayofyear'] = train.quote_date.dt.dayofyear
    train['dayofweek'] = train.quote_date.dt.dayofweek
    train['day'] = train.quote_date.dt.day
    
    test['year'] = test.quote_date.dt.year
    test['month'] = test.quote_date.dt.month
    test['dayofyear'] = test.quote_date.dt.dayofyear
    test['dayofweek'] = test.quote_date.dt.dayofweek
    test['day'] = test.quote_date.dt.day

    
    #print zip(train.day[100:110] , train.dayofweek[100:110] , train.quote_date[100:110])

    # drop useless columns and create labels




    #train = train.merge(specs, on = 'tube_assembly_id' , how = 'left')
    #test = test.merge(specs, on = 'tube_assembly_id' , how = 'left')
    train['num_comp'] = 0
    train['num_comp'] = num_items_train.row_sums.values  
    test['num_comp']  = 0
    test['num_comp']  = num_items_test.row_sums.values 
    train['num_spec'] = 0    
    train['num_spec'] = num_spec_train.counts.values
    test['num_spec']  = 0
    test['num_spec']  = num_spec_test.counts.values
    
    
   
     
    for i in ['SP.0063','SP.0012','SP.0080','SP.0007','SP.0026','SP.0082','SP.0069','SP.0070']:
       # if i == 'tube_assembly_id':
        #    print i            
            #continue
        train[i] = 0
        test[i] = 0
        train[i] = freq_spec_train[i]
        test[i] = freq_spec_test[i]



    idx = test.id.values.astype(int)
    test = test.drop(['supplier','material_id','id' ,  'quote_date' ,'tube_assembly_id' ,  'component_id_4', \
    'component_id_5', 'component_id_6', 'component_id_7',  'component_id_8','quantity_4','quantity_5','quantity_6','quantity_7','quantity_8'], axis = 1)
    labels = train.cost.values
    train = train.drop(['supplier','material_id' ,  'quote_date' ,'tube_assembly_id' ,  'component_id_4', \
    'component_id_5', 'component_id_6', 'component_id_7',  'component_id_8','quantity_4','quantity_5','quantity_6','quantity_7','quantity_8', 'cost' ], axis = 1)
   


    train.loc[ train.end_a_1x == 'N' ,'end_a_1x'] = 1
    train.loc[ train.end_a_2x == 'N' , 'end_a_2x'] = 1
    train.loc[ train.end_x_1x == 'N' , 'end_x_1x'] = 1
    train.loc[train.end_x_2x == 'N' ,  'end_x_2x'] = 1

    train.loc[ train.end_a_1x == 'Y' ,'end_a_1x'] = 0
    train.loc[ train.end_a_2x == 'Y' , 'end_a_2x'] = 0
    train.loc[ train.end_x_1x == 'Y' , 'end_x_1x'] = 0
    train.loc[train.end_x_2x == 'Y' ,  'end_x_2x'] = 0



    test.loc[test.end_a_1x == 'N' ,'end_a_1x'] = 1
    test.loc[test.end_a_2x == 'N' , 'end_a_2x'] = 1
    test.loc[test.end_x_1x == 'N' , 'end_x_1x'] = 1
    test.loc[test.end_x_2x == 'N' ,  'end_x_2x'] = 1
    test.loc[test.end_a_1x == 'Y' ,'end_a_1x'] = 0
    test.loc[test.end_a_2x == 'Y' , 'end_a_2x'] = 0
    test.loc[test.end_x_1x == 'Y' , 'end_x_1x'] = 0
    test.loc[test.end_x_2x == 'Y' ,  'end_x_2x'] = 0


    #print test.shape , train.shape
    #print train.columns.get_loc("end_a")
    #print train.columns
    # convert data to numpy array
    
    print '2',train.columns 
    
    
    train.loc[train.bracket_pricing == 'Yes', 'bracket_pricing' ] = 1
    train.loc[train.bracket_pricing == 'No', 'bracket_pricing' ] =  0
    
    test.loc[test.bracket_pricing == 'Yes', 'bracket_pricing' ] = 1
    test.loc[test.bracket_pricing == 'No', 'bracket_pricing' ] =  0 
    
    train.loc[train.end_a == 'Yes', 'end_a' ] = 1
    train.loc[train.end_a == 'No', 'end_a' ] = 0
    
    train.loc[train.end_x == 'Yes', 'end_x' ] = 1
    train.loc[train.end_x == 'No', 'end_x' ] = 0
    
    test.loc[test.end_a == 'Yes', 'end_a' ] = 1
    test.loc[test.end_a == 'No', 'end_a' ] = 0
    
    test.loc[test.end_x == 'Yes', 'end_x' ] = 1
    test.loc[test.end_x == 'No', 'end_x' ] = 0
    
   
    index = train.columns.get_loc('component_id_1')
    
    train1 = train
    test1 = test
    
    train = np.array(train)
    test = np.array(test)


    #print train.shape

    lbl = preprocessing.Binarizer()
    lbl.fit(list(train[:,index]) + list(test[:,index]) + list(train[:,index+2]) + list(test[:,index+2]) + list(train[:,index+4]) + list(test[:,index+4]))
    
    
    # label encode the categorical variables
    for i in range(train.shape[1]):
        if i in [index,index+2,index+4]:
            train[:,i] = lbl.transform(train[:,i])
            test[:,i] = lbl.transform(test[:,i])
            #print i,'asdla',train[1:100,i]
    





    
    # object array to float
    train = train.astype(float)
    test = test.astype(float)
    
    
    #gbm = ensemble.GradientBoostingRegressor(random_state=42, n_estimators = 3000, min_samples_split = 35, max_depth = 12 , learning_rate = .01 , max_features = 'sqrt' , loss = 'ls')
    """
    params = [{'n_estimators': [3000,3500], 'min_samples_split': [30,35],'max_depth': [11,12], 'min_samples_leaf':[1,2,3], \
    'learning_rate':[.009,0.01,.011] , 'max_features' :['sqrt', 'log2' ] , 'loss': ['ls']}]
       """       
    
    params = [{'n_estimators': [3500], 'min_samples_split': [30,35],'max_depth': [10,12] ,\
    'learning_rate':[0.009,0.01] , 'max_features' :['sqrt' ] , 'loss': ['ls']}]
    gbm = ensemble.GradientBoostingRegressor(random_state = 42)
    print 'kk'
    clf = grid_search.GridSearchCV(gbm,params, verbose=1, n_jobs = 2)
    label_log = np.log1p(labels)
    # cross validation
    print("k-Fold RMSLE:")
    #clf = grid_search.GridSearchCV(gbm, params, verbose=1 , n_jobs = 2)
    cv_rmsle = cross_validation.cross_val_score(clf, train, label_log, scoring='mean_squared_error')
    print(cv_rmsle)
    cv_rmsle = np.sqrt(np.abs(cv_rmsle))
    print(cv_rmsle), "asdasdad"
    print("Mean: " + str(cv_rmsle.mean()))
    
    # get predictions on test
    clf.fit(train, label_log)
    
    # get predictions from the model, convert them and dump them!
    preds = np.expm1(clf.predict(test))
    preds = pd.DataFrame({"id": idx, "cost": preds})
    preds.to_csv('gradboost_changed_name_withmean_median.csv', index=False)    
    
    
    
    
    
    """
    
    gbm = ensemble.GradientBoostingRegressor(random_state=42)

    params = [{'n_estimators': [3000,3500], 'min_samples_split': [30,35],'max_depth': [10,11,12], 'min_samples_leaf':[1,2,3],'subsample': [0.9,1.0], \
    'learning_rate':[.009,0.01,.011] , 'max_features' :['sqrt', 'log2' ] , 'loss': ['ls']}   ]
              
    params = [{'n_estimators': [2500, 3000], 'min_samples_split': [25,30],'max_depth': [12,13], 'min_samples_leaf':[1,2,3],\
    'learning_rate':[0.01] , 'max_features' :['sqrt'] , 'loss': ['ls']}]
    print 'kk'
    clf = grid_search.GridSearchCV(gbm,params, verbose=1 , n_jobs = 2)
    label_log = np.log1p(labels)
    # cross validation
    print("k-Fold RMSLE:")
    cv_rmsle = cross_validation.cross_val_score(clf, train, label_log, scoring='mean_squared_error')
    print(cv_rmsle)
    cv_rmsle = np.sqrt(np.abs(cv_rmsle))
    print(cv_rmsle), "asdasdad"
    print("Mean: " + str(cv_rmsle.mean()))
    
    # get predictions on test
    clf.fit(train, label_log)
    
    # get predictions from the model, convert them and dump them!
    preds = np.expm1(clf.predict(test))
    preds = pd.DataFrame({"id": idx, "cost": preds})
    preds.to_csv('gradboost_changed_name.csv', index=False)






label_log = np.log1p(labels)

# fit a gbm model
gbm = ensemble.GradientBoostingRegressor(random_state=42)
rf = ensemble.RandomForestRegressor()

# tune parameters
parameters = {"max_depth": [3, None] ,'n_estimators':(500,1000,1500,2000),'max_features' :['sqrt']}
clf = grid_search.GridSearchCV(rf, parameters, verbose=1)

# cross validation
print("k-Fold RMSLE:")
cv_rmsle = cross_validation.cross_val_score(clf, train, label_log, scoring='mean_squared_error')
print(cv_rmsle)
cv_rmsle = np.sqrt(np.abs(cv_rmsle))
print(cv_rmsle)
print("Mean: " + str(cv_rmsle.mean()))

# get predictions on test
clf.fit(train, label_log)

# get predictions from the model, convert them and dump them!
preds = np.expm1(clf.predict(test))
preds = pd.DataFrame({"id": idx, "cost": preds})
preds.to_csv('benchmark.csv', index=False)

"""
